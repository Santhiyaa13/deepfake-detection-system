{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923661ac",
   "metadata": {},
   "source": [
    "# Deepfake Detection using CNN\n",
    "**Objective:** Detect fake (deepfake) images using a convolutional neural network.\n",
    "\n",
    "**Technologies:** Python, TensorFlow, Keras, OpenCV\n",
    "\n",
    "**Author:** Santhiya K, Abinaya J, Devasudha S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ Load and Preprocess Dataset\n",
    "# This assumes you have 'real/' and 'fake/' image folders under 'dataset/train/' and 'dataset/test/'\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  Build CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ‹ï¸â€â™‚ï¸ Train the Model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ Evaluate Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612434cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Predict on New Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img('sample.jpg', target_size=(64, 64))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "print('Prediction:', 'Fake' if prediction[0][0] > 0.5 else 'Real')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}